{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {}\n",
    "credentials['CONSUMER_KEY'] = '_____________________'  \n",
    "credentials['CONSUMER_SECRET'] = '__________________________'  \n",
    "credentials['ACCESS_TOKEN'] = '____________________________'  \n",
    "credentials['ACCESS_SECRET'] = '___________________________'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python script which can fetch all the tweets(as many as allowed by Twitter API) done by midas@IIITD\n",
    "\n",
    "def get_all_tweets(screen_name, limit=199):\n",
    "    \n",
    "    # as maximum can be only 200\n",
    "    \n",
    "    # authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(credentials['CONSUMER_KEY'], credentials['CONSUMER_SECRET'])\n",
    "    auth.set_access_token(credentials['ACCESS_TOKEN'], credentials['ACCESS_SECRET'])\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    ScreenName_cursor = tweepy.Cursor(api.user_timeline, screen_name='midasIIITD')\n",
    "    \n",
    "    ScreenName_tweets = []\n",
    "    for tweet in ScreenName_cursor.items(limit):\n",
    "        ScreenName_tweets.append(tweet._json)\n",
    "        \n",
    "    \n",
    "    return ScreenName_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping into json.\n",
    "with open(\"tweets.json\", \"w\") as write_file:\n",
    "    json.dump(get_all_tweets(\"midasIIITD\"), write_file, skipkeys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets.json\", errors='ignore') as json_data:\n",
    "     all_tweets = json.load(json_data, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_tweets(all_tweets):\n",
    "    \n",
    "    # a list of all formatted tweets\n",
    "    tweet_list=[]\n",
    "    \n",
    "    for tweet in all_tweets:\n",
    "         # a dict to contain information about single tweet\n",
    "        tweet_information = dict()\n",
    "        \n",
    "        # text of tweet\n",
    "        tweet_information['text']=tweet['text']\n",
    "        \n",
    "        \n",
    "        # date and time at which tweet was created\n",
    "        tweet_information['created_at']=tweet['created_at']\n",
    "        \n",
    "        # favourites/likes count\n",
    "        tweet_information['favorite_count']=tweet['favorite_count']\n",
    "        \n",
    "        # retweet count\n",
    "        tweet_information['retweet_count']=tweet['retweet_count']\n",
    "        \n",
    "        # image count\n",
    "        \n",
    "        n = 0\n",
    "        try:\n",
    "            for media in tweet['extended_entities'][\"media\"]:\n",
    "                n=n+1\n",
    "        except:\n",
    "            n=n\n",
    "        if n>0:\n",
    "            tweet_information['number_of_images_posted_by_user']=n\n",
    "        else:\n",
    "            tweet_information['number_of_images_posted_by_user']=None\n",
    "            \n",
    "        \n",
    "        # add this tweet to the tweet_list\n",
    "        tweet_list.append(tweet_information)\n",
    "        \n",
    "    \n",
    "    return tweet_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = store_tweets(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>number_of_images_posted_by_user</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Apr 06 17:11:29 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @kdnuggets: Top 8 #Free Must-Read #Books on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Apr 06 16:43:27 +0000 2019</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>@nupur_baghel @PennDATS Congratulation @nupur_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Apr 05 16:08:37 +0000 2019</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>We have emailed the task details to all candid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Apr 05 04:05:11 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>RT @rfpvjr: Our NAACL paper on polarization in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Apr 05 04:04:43 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>RT @kdnuggets: Effective Transfer Learning For...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wed Apr 03 18:31:53 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>RT @stanfordnlp: What’s new in @Stanford CS224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wed Apr 03 17:04:32 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844</td>\n",
       "      <td>RT @DeepMindAI: Today we're releasing a large-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wed Apr 03 09:03:40 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>RT @ylecun: Congratulations Jitendra Malik !\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wed Apr 03 07:46:02 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @IIITDelhi: Another chance to take admissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tue Apr 02 04:20:13 +0000 2019</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @midasIIITD internship candidates who hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tue Apr 02 02:44:54 +0000 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Looking forward to your paper submission to @I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tue Apr 02 02:35:44 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>RT @ngrams: Reproducibility in multimedia rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mon Apr 01 06:53:08 +0000 2019</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Online application for https://t.co/DJFDrQsHZP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sun Mar 31 10:21:24 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>RT @ACMMM19: A final reminder of the Reproduci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fri Mar 29 19:43:24 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @isarth23: Thanks for the support and help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fri Mar 29 17:16:40 +0000 2019</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Since SemEval-2019 will be held June 6-7, 2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fri Mar 29 17:04:30 +0000 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>+@aggarwal_kartik.\\nCongrats! Wish you many mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fri Mar 29 17:03:29 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @aggarwal_kartik: Our work (@midasIIITD ) a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fri Mar 29 17:02:24 +0000 2019</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Congratulations! @midasIIITD team, @isarth23 @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fri Mar 29 05:35:22 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@EEMLcommunity @radamihalcea too many deadline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thu Mar 28 16:55:01 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>712</td>\n",
       "      <td>RT @stanfordnlp: CS224N Natural Language Proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thu Mar 28 16:54:37 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>RT @ylecun: Learn PyTorch by running on Google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wed Mar 27 16:09:09 +0000 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Dr. Vineeth N Balasubramanian will present a T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wed Mar 27 11:53:40 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1544</td>\n",
       "      <td>RT @ylecun: I am extremely honored to be the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tue Mar 26 18:12:27 +0000 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Thanks to all shortlisted candidates for submi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tue Mar 26 05:54:49 +0000 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@IEEEBigMM19 @ACMMM19 and 6 days left for work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Tue Mar 26 05:50:10 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>RT @IEEEBigMM19: Hurry Up!\\n6 Days left for Ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mon Mar 25 13:01:57 +0000 2019</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Congratulations @midasIIITD students Simra Sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sun Mar 24 18:44:01 +0000 2019</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>The last date for submitting a solution for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sun Mar 24 18:26:02 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @IIITDelhi: @IIITDelhi invites application ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Thu Feb 21 06:39:27 +0000 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@IIITDelhi has initiated PhD Admission 2019 pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Thu Feb 21 04:48:24 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>RT @radamihalcea: We tend to focus mainly on c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Wed Feb 20 07:09:19 +0000 2019</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>@RealAAAI @RatnRajiv Thanks, @RealAAAI for rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Wed Feb 20 05:38:29 +0000 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Deepak Gupta, has joined @Google today. \\nEarl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Tue Feb 19 17:16:24 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>RT @ACMMM19: We are pleased to announce the mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Tue Feb 19 04:29:33 +0000 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>In addition to projects related to NLP and Mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Tue Feb 19 04:19:05 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289</td>\n",
       "      <td>RT @technology: What could the manufacturing i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Tue Feb 19 04:18:53 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>RT @MSFTResearch: Dr. Layla El Asri wants you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Mon Feb 18 17:29:44 +0000 2019</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>To apply for @midasIIITD internship at @IIITDe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Mon Feb 18 05:37:59 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>RT @CornellDyson: Digital ag is Cornell’s newe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Sun Feb 17 17:22:06 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>RT @odsc: Introduction to StanfordNLP: a state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Sun Feb 17 09:02:28 +0000 2019</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Looking forward to your participation in Multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Sun Feb 17 08:49:36 +0000 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Consider attending National Workshop on Intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Sun Feb 17 06:39:30 +0000 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Submissions are invited for a special issue of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Sat Feb 16 16:57:51 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @debanjanbhucs: https://t.co/qNFzJ7ZHki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Fri Feb 15 08:22:23 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>RT @MSFTResearch: Congratulations to Manik Var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Thu Feb 14 15:56:14 +0000 2019</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Congratulations! Anupam Samanta on joining @Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Wed Feb 13 18:56:13 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>RT @kdnuggets: Using BERT for state-of-the-art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Wed Feb 13 15:54:52 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>RT @ACMMM19: Attention authors of ACM MultiMed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Wed Feb 13 05:56:05 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>RT @kdnuggets: 9 Must-have skills you need to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Thu Feb 07 19:21:52 +0000 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@ACMMM19 @ACM Just one week is left for worksh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Thu Feb 07 15:49:59 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@NilayShri @the_dhumketu Thanks, @NilayShri fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Thu Feb 07 15:49:08 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @NilayShri: @midasIIITD @the_dhumketu this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Thu Feb 07 06:23:10 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>RT @kdnuggets: Machine Learning in Python by @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Wed Feb 06 11:26:25 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>RT @Cambridge_Uni: .@DeepMindAI and @Cambridge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Tue Feb 05 18:32:54 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212</td>\n",
       "      <td>RT @GoogleAI: Google AI  and @DeepMindAI resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tue Feb 05 17:45:09 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Edit: In the updated leaderboard we are now ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tue Feb 05 17:44:27 +0000 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Congratulations! @isarth23. \\nIt is our pleasu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tue Feb 05 12:09:44 +0000 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>In addition to OffensEval task, @midasIIITD ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tue Feb 05 11:55:41 +0000 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Thanks, Karan Uppal and @RatnRajiv for all you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  favorite_count  \\\n",
       "0   Sat Apr 06 17:11:29 +0000 2019               0   \n",
       "1   Sat Apr 06 16:43:27 +0000 2019              10   \n",
       "2   Fri Apr 05 16:08:37 +0000 2019               8   \n",
       "3   Fri Apr 05 04:05:11 +0000 2019               0   \n",
       "4   Fri Apr 05 04:04:43 +0000 2019               0   \n",
       "5   Wed Apr 03 18:31:53 +0000 2019               0   \n",
       "6   Wed Apr 03 17:04:32 +0000 2019               0   \n",
       "7   Wed Apr 03 09:03:40 +0000 2019               0   \n",
       "8   Wed Apr 03 07:46:02 +0000 2019               0   \n",
       "9   Tue Apr 02 04:20:13 +0000 2019               8   \n",
       "10  Tue Apr 02 02:44:54 +0000 2019               5   \n",
       "11  Tue Apr 02 02:35:44 +0000 2019               0   \n",
       "12  Mon Apr 01 06:53:08 +0000 2019               7   \n",
       "13  Sun Mar 31 10:21:24 +0000 2019               0   \n",
       "14  Fri Mar 29 19:43:24 +0000 2019               0   \n",
       "15  Fri Mar 29 17:16:40 +0000 2019               9   \n",
       "16  Fri Mar 29 17:04:30 +0000 2019               2   \n",
       "17  Fri Mar 29 17:03:29 +0000 2019               0   \n",
       "18  Fri Mar 29 17:02:24 +0000 2019               9   \n",
       "19  Fri Mar 29 05:35:22 +0000 2019               0   \n",
       "20  Thu Mar 28 16:55:01 +0000 2019               0   \n",
       "21  Thu Mar 28 16:54:37 +0000 2019               0   \n",
       "22  Wed Mar 27 16:09:09 +0000 2019               4   \n",
       "23  Wed Mar 27 11:53:40 +0000 2019               0   \n",
       "24  Tue Mar 26 18:12:27 +0000 2019               5   \n",
       "25  Tue Mar 26 05:54:49 +0000 2019               2   \n",
       "26  Tue Mar 26 05:50:10 +0000 2019               0   \n",
       "27  Mon Mar 25 13:01:57 +0000 2019              18   \n",
       "28  Sun Mar 24 18:44:01 +0000 2019               8   \n",
       "29  Sun Mar 24 18:26:02 +0000 2019               0   \n",
       "..                             ...             ...   \n",
       "70  Thu Feb 21 06:39:27 +0000 2019               2   \n",
       "71  Thu Feb 21 04:48:24 +0000 2019               0   \n",
       "72  Wed Feb 20 07:09:19 +0000 2019               6   \n",
       "73  Wed Feb 20 05:38:29 +0000 2019               4   \n",
       "74  Tue Feb 19 17:16:24 +0000 2019               0   \n",
       "75  Tue Feb 19 04:29:33 +0000 2019               3   \n",
       "76  Tue Feb 19 04:19:05 +0000 2019               0   \n",
       "77  Tue Feb 19 04:18:53 +0000 2019               0   \n",
       "78  Mon Feb 18 17:29:44 +0000 2019              11   \n",
       "79  Mon Feb 18 05:37:59 +0000 2019               0   \n",
       "80  Sun Feb 17 17:22:06 +0000 2019               0   \n",
       "81  Sun Feb 17 09:02:28 +0000 2019               3   \n",
       "82  Sun Feb 17 08:49:36 +0000 2019               1   \n",
       "83  Sun Feb 17 06:39:30 +0000 2019               1   \n",
       "84  Sat Feb 16 16:57:51 +0000 2019               0   \n",
       "85  Fri Feb 15 08:22:23 +0000 2019               0   \n",
       "86  Thu Feb 14 15:56:14 +0000 2019              14   \n",
       "87  Wed Feb 13 18:56:13 +0000 2019               0   \n",
       "88  Wed Feb 13 15:54:52 +0000 2019               0   \n",
       "89  Wed Feb 13 05:56:05 +0000 2019               0   \n",
       "90  Thu Feb 07 19:21:52 +0000 2019               1   \n",
       "91  Thu Feb 07 15:49:59 +0000 2019               0   \n",
       "92  Thu Feb 07 15:49:08 +0000 2019               0   \n",
       "93  Thu Feb 07 06:23:10 +0000 2019               0   \n",
       "94  Wed Feb 06 11:26:25 +0000 2019               0   \n",
       "95  Tue Feb 05 18:32:54 +0000 2019               0   \n",
       "96  Tue Feb 05 17:45:09 +0000 2019               0   \n",
       "97  Tue Feb 05 17:44:27 +0000 2019               4   \n",
       "98  Tue Feb 05 12:09:44 +0000 2019               5   \n",
       "99  Tue Feb 05 11:55:41 +0000 2019               1   \n",
       "\n",
       "    number_of_images_posted_by_user  retweet_count  \\\n",
       "0                               NaN              2   \n",
       "1                               NaN              3   \n",
       "2                               NaN              1   \n",
       "3                               NaN             16   \n",
       "4                               1.0             10   \n",
       "5                               NaN             57   \n",
       "6                               NaN            844   \n",
       "7                               NaN             16   \n",
       "8                               NaN              4   \n",
       "9                               NaN              1   \n",
       "10                              NaN              1   \n",
       "11                              NaN              7   \n",
       "12                              NaN              2   \n",
       "13                              NaN             10   \n",
       "14                              NaN              2   \n",
       "15                              NaN              1   \n",
       "16                              NaN              0   \n",
       "17                              NaN              1   \n",
       "18                              NaN              1   \n",
       "19                              NaN              0   \n",
       "20                              NaN            712   \n",
       "21                              NaN            157   \n",
       "22                              NaN              1   \n",
       "23                              NaN           1544   \n",
       "24                              NaN              1   \n",
       "25                              NaN              0   \n",
       "26                              NaN              3   \n",
       "27                              NaN              1   \n",
       "28                              NaN              3   \n",
       "29                              NaN              4   \n",
       "..                              ...            ...   \n",
       "70                              NaN              1   \n",
       "71                              NaN             13   \n",
       "72                              NaN              3   \n",
       "73                              NaN              2   \n",
       "74                              NaN             15   \n",
       "75                              NaN              2   \n",
       "76                              NaN            289   \n",
       "77                              NaN             21   \n",
       "78                              NaN              9   \n",
       "79                              NaN              6   \n",
       "80                              NaN             51   \n",
       "81                              NaN              1   \n",
       "82                              NaN              0   \n",
       "83                              NaN              1   \n",
       "84                              NaN              1   \n",
       "85                              NaN             13   \n",
       "86                              NaN              4   \n",
       "87                              1.0              5   \n",
       "88                              NaN             11   \n",
       "89                              1.0             11   \n",
       "90                              NaN              1   \n",
       "91                              NaN              0   \n",
       "92                              NaN              1   \n",
       "93                              NaN             54   \n",
       "94                              NaN             35   \n",
       "95                              NaN            212   \n",
       "96                              NaN              0   \n",
       "97                              NaN              0   \n",
       "98                              NaN              1   \n",
       "99                              NaN              1   \n",
       "\n",
       "                                                 text  \n",
       "0   RT @kdnuggets: Top 8 #Free Must-Read #Books on...  \n",
       "1   @nupur_baghel @PennDATS Congratulation @nupur_...  \n",
       "2   We have emailed the task details to all candid...  \n",
       "3   RT @rfpvjr: Our NAACL paper on polarization in...  \n",
       "4   RT @kdnuggets: Effective Transfer Learning For...  \n",
       "5   RT @stanfordnlp: What’s new in @Stanford CS224...  \n",
       "6   RT @DeepMindAI: Today we're releasing a large-...  \n",
       "7   RT @ylecun: Congratulations Jitendra Malik !\\n...  \n",
       "8   RT @IIITDelhi: Another chance to take admissio...  \n",
       "9   Dear @midasIIITD internship candidates who hav...  \n",
       "10  Looking forward to your paper submission to @I...  \n",
       "11  RT @ngrams: Reproducibility in multimedia rese...  \n",
       "12  Online application for https://t.co/DJFDrQsHZP...  \n",
       "13  RT @ACMMM19: A final reminder of the Reproduci...  \n",
       "14  RT @isarth23: Thanks for the support and help ...  \n",
       "15  Since SemEval-2019 will be held June 6-7, 2019...  \n",
       "16  +@aggarwal_kartik.\\nCongrats! Wish you many mo...  \n",
       "17  RT @aggarwal_kartik: Our work (@midasIIITD ) a...  \n",
       "18  Congratulations! @midasIIITD team, @isarth23 @...  \n",
       "19  @EEMLcommunity @radamihalcea too many deadline...  \n",
       "20  RT @stanfordnlp: CS224N Natural Language Proce...  \n",
       "21  RT @ylecun: Learn PyTorch by running on Google...  \n",
       "22  Dr. Vineeth N Balasubramanian will present a T...  \n",
       "23  RT @ylecun: I am extremely honored to be the r...  \n",
       "24  Thanks to all shortlisted candidates for submi...  \n",
       "25  @IEEEBigMM19 @ACMMM19 and 6 days left for work...  \n",
       "26  RT @IEEEBigMM19: Hurry Up!\\n6 Days left for Ab...  \n",
       "27  Congratulations @midasIIITD students Simra Sha...  \n",
       "28  The last date for submitting a solution for th...  \n",
       "29  RT @IIITDelhi: @IIITDelhi invites application ...  \n",
       "..                                                ...  \n",
       "70  @IIITDelhi has initiated PhD Admission 2019 pr...  \n",
       "71  RT @radamihalcea: We tend to focus mainly on c...  \n",
       "72  @RealAAAI @RatnRajiv Thanks, @RealAAAI for rec...  \n",
       "73  Deepak Gupta, has joined @Google today. \\nEarl...  \n",
       "74  RT @ACMMM19: We are pleased to announce the mu...  \n",
       "75  In addition to projects related to NLP and Mul...  \n",
       "76  RT @technology: What could the manufacturing i...  \n",
       "77  RT @MSFTResearch: Dr. Layla El Asri wants you ...  \n",
       "78  To apply for @midasIIITD internship at @IIITDe...  \n",
       "79  RT @CornellDyson: Digital ag is Cornell’s newe...  \n",
       "80  RT @odsc: Introduction to StanfordNLP: a state...  \n",
       "81  Looking forward to your participation in Multi...  \n",
       "82  Consider attending National Workshop on Intell...  \n",
       "83  Submissions are invited for a special issue of...  \n",
       "84         RT @debanjanbhucs: https://t.co/qNFzJ7ZHki  \n",
       "85  RT @MSFTResearch: Congratulations to Manik Var...  \n",
       "86  Congratulations! Anupam Samanta on joining @Go...  \n",
       "87  RT @kdnuggets: Using BERT for state-of-the-art...  \n",
       "88  RT @ACMMM19: Attention authors of ACM MultiMed...  \n",
       "89  RT @kdnuggets: 9 Must-have skills you need to ...  \n",
       "90  @ACMMM19 @ACM Just one week is left for worksh...  \n",
       "91  @NilayShri @the_dhumketu Thanks, @NilayShri fo...  \n",
       "92  RT @NilayShri: @midasIIITD @the_dhumketu this ...  \n",
       "93  RT @kdnuggets: Machine Learning in Python by @...  \n",
       "94  RT @Cambridge_Uni: .@DeepMindAI and @Cambridge...  \n",
       "95  RT @GoogleAI: Google AI  and @DeepMindAI resea...  \n",
       "96  Edit: In the updated leaderboard we are now ra...  \n",
       "97  Congratulations! @isarth23. \\nIt is our pleasu...  \n",
       "98  In addition to OffensEval task, @midasIIITD ha...  \n",
       "99  Thanks, Karan Uppal and @RatnRajiv for all you...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
